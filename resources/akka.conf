include "akka/discovery.conf"
include "akka/logging.conf"
include "akka/cluster.conf"
include "akka/remote.conf"
include "akka/managment.conf"
include "akka/actor.conf"
include "akka/test.conf"
include "akka/paralellism/default-dispatcher.conf"

akka {
  coordinated-shutdown.exit-jvm = on
  io.dns.resolver = async-dns
}

#   Batch writes
#   To optimize throughput, a persistent actor internally batches
#   events to be stored under high load
#   before writing them to the journal (as a single batch).
#   The batch size dynamically grows from 1 under low and moderate loads to
#   a configurable maximum size (default is 200) under high load.
#
#   When using persistAsync this increases the maximum throughput dramatically.
akka.persistence.journal.max-message-batch-size = 2000

hardwareSpecs {

    # Min number of threads to cap factor-based parallelism number to
    parallelismMin = 4
    parallelismMin = ${?parallelismMin}
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelismFactor = 1
    # Max number of threads to cap factor-based parallelism number to
    parallelismMax = 12
    parallelismMax = ${?parallelismMax}



    # Throughput defines the maximum number of messages to be
    # processed per actor before the thread jumps to the next actor.
    # Set to 1 for as fair as possible.

    #
    # There are a few edge cases.
    # If you have a case where the number of threads is equal to the number of actors
    # using the dispatcher, set the number extremely high, like 1000.

    # If your actors perform tasks that will take some time to complete
    # and you need fairness to avoid starvation of other actors sharing the pool,
    # set the throughput to 1.
    #
     processedMessagesPerActorPerThreadJump = 1 # https://letitcrash.com/post/40755146949/tuning-dispatchers-in-akka-applications

}


# Default persistence extension settings.
akka.persistence {

    # When starting many persistent actors at the same time the journal
    # and its data store is protected from being overloaded by limiting number
    # of recoveries that can be in progress at the same time. When
    # exceeding the limit the actors will wait until other recoveries have
    # been completed.
    # max-concurrent-recoveries = 50
    max-concurrent-recoveries = 500
}